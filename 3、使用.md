# 使用示例应用程序
Distiller仓库包含一个示例应用程序，即Distiller /examples/classifier_compression/compress_classifier。和一组演示Distiller特性的调度文件。下面是如何使用这个应用程序和附带的计划的简短讨论。
你也可以参考以下资源:
- 调度程序文件格式的[解释](调度程序文件格式的解释) 。
- 深入[讨论](https://nervanasystems.github.io/distiller/model_zoo.html) 我们如何使用这些时间表文件来实现几个最先进的DNN压缩研究论文。

示例应用程序支持图像分类DNNs的各种压缩特性，并提供了一个如何在您自己的应用程序中集成蒸馏器的示例。<br>
代码被记录下来，应该被认为是最好的文档来源，但是我们在这里提供一些详细阐述。

这个图显示了compress_classider.py在压缩工作流程中的位置，以及我们如何将Jupyter笔记本集成为我们研究工作的一部分。
![img](.\img\use-flow.png)

## 命令行参数
要获得关于命令行参数的帮助，调用:
```shell script
$ python3 compress_classifier.py --help
```
例如：
```shell script
$ time python3 compress_classifier.py -a alexnet --lr 0.005 -p 50 ../../../data.imagenet -j 44 --epochs 90 --pretrained --compress=../sensitivity-pruning/alexnet.schedule_sensitivity.yaml

Parameters:
 +----+---------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
 |    | Name                      | Shape            |   NNZ (dense) |   NNZ (sparse) |   Cols (%) |   Rows (%) |   Ch (%) |   2D (%) |   3D (%) |   Fine (%) |     Std |     Mean |   Abs-Mean |
 |----+---------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------|
 |  0 | features.module.0.weight  | (64, 3, 11, 11)  |         23232 |          13411 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |   42.27359 | 0.14391 | -0.00002 |    0.08805 |
 |  1 | features.module.3.weight  | (192, 64, 5, 5)  |        307200 |         115560 |    0.00000 |    0.00000 |  0.00000 |  1.91243 |  0.00000 |   62.38281 | 0.04703 | -0.00250 |    0.02289 |
 |  2 | features.module.6.weight  | (384, 192, 3, 3) |        663552 |         256565 |    0.00000 |    0.00000 |  0.00000 |  6.18490 |  0.00000 |   61.33445 | 0.03354 | -0.00184 |    0.01803 |
 |  3 | features.module.8.weight  | (256, 384, 3, 3) |        884736 |         315065 |    0.00000 |    0.00000 |  0.00000 |  6.96411 |  0.00000 |   64.38881 | 0.02646 | -0.00168 |    0.01422 |
 |  4 | features.module.10.weight | (256, 256, 3, 3) |        589824 |         186938 |    0.00000 |    0.00000 |  0.00000 | 15.49225 |  0.00000 |   68.30614 | 0.02714 | -0.00246 |    0.01409 |
 |  5 | classifier.1.weight       | (4096, 9216)     |      37748736 |        3398881 |    0.00000 |    0.21973 |  0.00000 |  0.21973 |  0.00000 |   90.99604 | 0.00589 | -0.00020 |    0.00168 |
 |  6 | classifier.4.weight       | (4096, 4096)     |      16777216 |        1782769 |    0.21973 |    3.46680 |  0.00000 |  3.46680 |  0.00000 |   89.37387 | 0.00849 | -0.00066 |    0.00263 |
 |  7 | classifier.6.weight       | (1000, 4096)     |       4096000 |         994738 |    3.36914 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |   75.71440 | 0.01718 |  0.00030 |    0.00778 |
 |  8 | Total sparsity:           | -                |      61090496 |        7063928 |    0.00000 |    0.00000 |  0.00000 |  0.00000 |  0.00000 |   88.43694 | 0.00000 |  0.00000 |    0.00000 |
 +----+---------------------------+------------------+---------------+----------------+------------+------------+----------+----------+----------+------------+---------+----------+------------+
 2018-04-04 21:30:52,499 - Total sparsity: 88.44

 2018-04-04 21:30:52,499 - --- validate (epoch=89)-----------
 2018-04-04 21:30:52,499 - 128116 samples (256 per mini-batch)
 2018-04-04 21:31:04,646 - Epoch: [89][   50/  500]    Loss 2.175988    Top1 51.289063    Top5 74.023438
 2018-04-04 21:31:06,427 - Epoch: [89][  100/  500]    Loss 2.171564    Top1 51.175781    Top5 74.308594
 2018-04-04 21:31:11,432 - Epoch: [89][  150/  500]    Loss 2.159347    Top1 51.546875    Top5 74.473958
 2018-04-04 21:31:14,364 - Epoch: [89][  200/  500]    Loss 2.156857    Top1 51.585938    Top5 74.568359
 2018-04-04 21:31:18,381 - Epoch: [89][  250/  500]    Loss 2.152790    Top1 51.707813    Top5 74.681250
 2018-04-04 21:31:22,195 - Epoch: [89][  300/  500]    Loss 2.149962    Top1 51.791667    Top5 74.755208
 2018-04-04 21:31:25,508 - Epoch: [89][  350/  500]    Loss 2.150936    Top1 51.827009    Top5 74.767857
 2018-04-04 21:31:29,538 - Epoch: [89][  400/  500]    Loss 2.150853    Top1 51.781250    Top5 74.763672
 2018-04-04 21:31:32,842 - Epoch: [89][  450/  500]    Loss 2.150156    Top1 51.828125    Top5 74.821181
 2018-04-04 21:31:35,338 - Epoch: [89][  500/  500]    Loss 2.150417    Top1 51.833594    Top5 74.817187
 2018-04-04 21:31:35,357 - ==> Top1: 51.838    Top5: 74.817    Loss: 2.150

 2018-04-04 21:31:35,364 - Saving checkpoint
 2018-04-04 21:31:39,251 - --- test ---------------------
 2018-04-04 21:31:39,252 - 50000 samples (256 per mini-batch)
 2018-04-04 21:31:51,512 - Test: [   50/  195]    Loss 1.487607    Top1 63.273438    Top5 85.695312
 2018-04-04 21:31:55,015 - Test: [  100/  195]    Loss 1.638043    Top1 60.636719    Top5 83.664062
 2018-04-04 21:31:58,732 - Test: [  150/  195]    Loss 1.833214    Top1 57.619792    Top5 80.447917
 2018-04-04 21:32:01,274 - ==> Top1: 56.606    Top5: 79.446    Loss: 1.893
```
让我们再看看命令行:
```shell script
$ time python3 compress_classifier.py -a alexnet --lr 0.005 -p 50 ../../../data.imagenet -j 44 --epochs 90 --pretrained --compress=../sensitivity-pruning/alexnet.schedule_sensitivity.yaml
```
在这个例子中，我们使用以下配置对TorchVision预先训练好的AlexNet网络进行修剪:
+ 0.005的学习速率
+ 每50个小批量打印进度。
+ 使用44个工作线程来加载数据(确保使用适合您的机器的线程)。
+ 跑90个epchs。Torchvision的预训练模型不存储epoch元数据，因此剪枝从epoch 0开始。当你训练和修剪你自己的网络时，最后的训练纪元被保存为模型的元数据。因此，当你加载这些模型时，第一个epch不是0，但它是最后一个训练epoch。
+ 修剪schedules在alexnet.schedule_sensitivy.yaml中提供
日志文件被写入logs目录。

## 一些例子
Distiller提供了几个示例schedules，可以与compress_classifiere .py一起使用。这些示例调度(YAML)文件包含用于调用调度的命令行(以便您可以在您的环境中轻松地重新创建结果)，以及修剪或正则化的结果。结果通常包含一个表，显示每个模型参数的稀疏性，以及验证和测试top1, top5和损失分数。

有关示例schedules的更多细节，您可以参考[Model Zoo](https://nervanasystems.github.io/distiller/model_zoo.html) 。

+ examples/agp-pruning
    + 自动逐步修剪(AGP)在MobileNet和ResNet18 (ImageNet数据集)
+ examples/hybrid:
    - 带有2D(内核)正则化的AlexNet AGP (ImageNet数据集)
    - AlexNet敏感性剪枝与2D正则化
    
+ examples/network_slimming:
    + ResNet20网络瘦身(这是正在进行的工作)

+ examples/pruning_filters_for_efficient_convnets:
    + ResNet56 baseline training (CIFAR10 dataset)
    + ResNet56 filter removal using filter ranking
+ examples/sensitivity_analysis:
    + Element-wise修剪敏感性分析:
    + AlexNet (ImageNet)
    + MobileNet (ImageNet)
    + ResNet18 (ImageNet)
    + ResNet20 (CIFAR10)
    + ResNet34 (ImageNet)
    + Filter-wise修剪敏感性分析:
    + ResNet20 (CIFAR10)
    + ResNet56 (CIFAR10)
+ examples/sensitivity-pruning:
    + AlexNet敏感性剪枝与迭代剪枝
    + AlexNet敏感性剪枝与一次性剪枝
    
+ examples/ssl:
    + ResNet20 baseline训练(CIFAR10数据集)
    + ResNet20上带层移除的结构化稀疏性学习(SSL)
    + 在ResNet20上删除通道的SSL
+ examples/quantization:
    + AlexNet w. Batch-Norm (base FP32 + DoReFa)
    + Pre-activation ResNet20 on CIFAR10 (base FP32 + DoReFa)
    + Pre-activation ResNet18 on ImageNEt (base FP32 + DoReFa)


## 实验重现性
实验的重现性有时很重要。Pete Warden最近在他的[博客](https://petewarden.com/2018/03/19/the-machine-learning-reproducibility-crisis/) 中阐述了这一点。
PyTorch对确定性执行的支持要求我们只使用一个线程来加载数据(另一方面，数据加载器的多线程执行可以创建随机顺序并改变结果)，并设置CPU和GPU PRNGs的种子。使用——deterministic命令行标志并设置j=1将产生可重现的结果(对于相同的PyTorch版本)。

## 进行剪枝敏感性分析
Distiller支持element-wise和 filter-wise 的修剪敏感性分析。在这两种情况下，都使用L1-norm对要删除的元素或过滤器进行排序。例如，在进行滤波修剪灵敏度分析时，计算各层权重张量的滤波器的1-范数，并将底部的x%设为0。<br>
分析过程相当长，因为目前我们使用整个测试数据集来评估每个权值张量在每个修剪级别上的精度性能。使用一个小数据集可以节省很多时间，我们计划评估它是否能提供足够的结果。<br>
结果输出为CSV文件(sensitivity.csv)和PNG文件(sensitivity.png)。实现在distiller/sensitivy.py中，它包含有关进程和CSV文件格式的进一步细节。

下面的例子在CIFAR10的ResNet20上执行 element-wise的修剪敏感性分析:
```shell script
$ python3 compress_classifier.py -a resnet20_cifar ../../../data.cifar10/ -j=1 --resume=../cifar10/resnet20/checkpoint_trained_dense.pth.tar --sense=element
```
sense命令行参数可以设置为element或filter，这取决于您想要完成的分析类型。

还有一个[Jupyter笔记本](http://localhost:8888/notebooks/sensitivity_analysis.ipynb)，上面有调用、输出和解释的示例。


## 训练后量化
：下面的例子对用于ImageNetResNet18做量化:
```shell script
$ python3 compress_classifier.py -a resnet18 ../../../data.imagenet  --pretrained --quantize-eval --evaluate
```
有关如何从命令行调用训练后量化的详细信息，请参见[此处](https://nervanasystems.github.io/distiller/schedule.html#post-training-quantization)。

使用量化模型的checkpoint 将转储到运行目录中。它将包含量化的模型参数(数据类型仍然是FP32，但值将是整数)。计算的量化参数(尺度和零点)也存储在每个量化层中。

更多训练后量化的例子见[这里](https://github.com/NervanaSystems/distiller/blob/master/examples/quantization/post_train_quant)。

## 总结
您可以使用示例压缩应用程序来生成模型摘要报告，例如属性和计算摘要报告(参见下面的屏幕截图)。您可以记录稀疏性统计信息(写入控制台和CSV文件)、性能、优化器和模型信息，还可以创建DNN的PNG图像。
创建一个PNG图像是一个实验特性(它依赖的特性在PyTorch 1.3中是不可用的，我们希望在PyTorch的下一个版本中可以使用)，所以要使用它，你需要编译PyTorch主分支，并希望是最好的;-)。
```shell script
$ python3 compress_classifier.py --resume=../ssl/checkpoints/checkpoint_trained_ch_regularized_dense.pth.tar -a=resnet20_cifar ../../../data.cifar10 --summary=compute
```
生成:
```shell script
+----+------------------------------+--------+----------+-----------------+--------------+-----------------+--------------+------------------+---------+
|    | Name                         | Type   | Attrs    | IFM             |   IFM volume | OFM             |   OFM volume |   Weights volume |    MACs |
|----+------------------------------+--------+----------+-----------------+--------------+-----------------+--------------+------------------+---------|
|  0 | module.conv1                 | Conv2d | k=(3, 3) | (1, 3, 32, 32)  |         3072 | (1, 16, 32, 32) |        16384 |              432 |  442368 |
|  1 | module.layer1.0.conv1        | Conv2d | k=(3, 3) | (1, 16, 32, 32) |        16384 | (1, 16, 32, 32) |        16384 |             2304 | 2359296 |
|  2 | module.layer1.0.conv2        | Conv2d | k=(3, 3) | (1, 16, 32, 32) |        16384 | (1, 16, 32, 32) |        16384 |             2304 | 2359296 |
|  3 | module.layer1.1.conv1        | Conv2d | k=(3, 3) | (1, 16, 32, 32) |        16384 | (1, 16, 32, 32) |        16384 |             2304 | 2359296 |
|  4 | module.layer1.1.conv2        | Conv2d | k=(3, 3) | (1, 16, 32, 32) |        16384 | (1, 16, 32, 32) |        16384 |             2304 | 2359296 |
|  5 | module.layer1.2.conv1        | Conv2d | k=(3, 3) | (1, 16, 32, 32) |        16384 | (1, 16, 32, 32) |        16384 |             2304 | 2359296 |
|  6 | module.layer1.2.conv2        | Conv2d | k=(3, 3) | (1, 16, 32, 32) |        16384 | (1, 16, 32, 32) |        16384 |             2304 | 2359296 |
|  7 | module.layer2.0.conv1        | Conv2d | k=(3, 3) | (1, 16, 32, 32) |        16384 | (1, 32, 16, 16) |         8192 |             4608 | 1179648 |
|  8 | module.layer2.0.conv2        | Conv2d | k=(3, 3) | (1, 32, 16, 16) |         8192 | (1, 32, 16, 16) |         8192 |             9216 | 2359296 |
|  9 | module.layer2.0.downsample.0 | Conv2d | k=(1, 1) | (1, 16, 32, 32) |        16384 | (1, 32, 16, 16) |         8192 |              512 |  131072 |
| 10 | module.layer2.1.conv1        | Conv2d | k=(3, 3) | (1, 32, 16, 16) |         8192 | (1, 32, 16, 16) |         8192 |             9216 | 2359296 |
| 11 | module.layer2.1.conv2        | Conv2d | k=(3, 3) | (1, 32, 16, 16) |         8192 | (1, 32, 16, 16) |         8192 |             9216 | 2359296 |
| 12 | module.layer2.2.conv1        | Conv2d | k=(3, 3) | (1, 32, 16, 16) |         8192 | (1, 32, 16, 16) |         8192 |             9216 | 2359296 |
| 13 | module.layer2.2.conv2        | Conv2d | k=(3, 3) | (1, 32, 16, 16) |         8192 | (1, 32, 16, 16) |         8192 |             9216 | 2359296 |
| 14 | module.layer3.0.conv1        | Conv2d | k=(3, 3) | (1, 32, 16, 16) |         8192 | (1, 64, 8, 8)   |         4096 |            18432 | 1179648 |
| 15 | module.layer3.0.conv2        | Conv2d | k=(3, 3) | (1, 64, 8, 8)   |         4096 | (1, 64, 8, 8)   |         4096 |            36864 | 2359296 |
| 16 | module.layer3.0.downsample.0 | Conv2d | k=(1, 1) | (1, 32, 16, 16) |         8192 | (1, 64, 8, 8)   |         4096 |             2048 |  131072 |
| 17 | module.layer3.1.conv1        | Conv2d | k=(3, 3) | (1, 64, 8, 8)   |         4096 | (1, 64, 8, 8)   |         4096 |            36864 | 2359296 |
| 18 | module.layer3.1.conv2        | Conv2d | k=(3, 3) | (1, 64, 8, 8)   |         4096 | (1, 64, 8, 8)   |         4096 |            36864 | 2359296 |
| 19 | module.layer3.2.conv1        | Conv2d | k=(3, 3) | (1, 64, 8, 8)   |         4096 | (1, 64, 8, 8)   |         4096 |            36864 | 2359296 |
| 20 | module.layer3.2.conv2        | Conv2d | k=(3, 3) | (1, 64, 8, 8)   |         4096 | (1, 64, 8, 8)   |         4096 |            36864 | 2359296 |
| 21 | module.fc                    | Linear |          | (1, 64)         |           64 | (1, 10)         |           10 |              640 |     640 |
+----+------------------------------+--------+----------+-----------------+--------------+-----------------+--------------+------------------+---------+
Total MACs: 40,813,184
```

##使用TensorBoard
谷歌的[TensorBoard](https://github.com/tensorflow/tensorboard)是一个很好的工具，可视化的进展，DNN的培训。Distiller的日志记录器支持以文件格式写入性能指示器和参数统计信息，这些文件格式可以被TensorBoard读取(蒸馏器使用TensorFlow的api来完成这项工作，这就是为什么蒸馏器需要安装TensorFlow)。<br>
要查看这些图，请调用TensorBoard服务器。例如:
```shell script
$ tensorboard --logdir=logs
```
蒸馏器的设置(requirements.txt)为CPU安装了TensorFlow。如果您想要不同的安装，请遵循[TensorFlow安装说明](https://www.tensorflow.org/install/install_linux)。


##收集激活统计数据
在具有ReLU层的cnn中，ReLU激活函数(特征图)也表现出良好的稀疏度(典型的稀疏度为50-60%)。
可以使用 ```——act_stats``` 命令行标志收集激活统计信息。
例如
```shell script
$ python3 compress_classifier.py -a=resnet56_cifar -p=50 ../../../data.cifar10  --resume=checkpoint.resnet56_cifar_baseline.pth.tar --act-stats=test -e
```
```test```参数表明，在本例中，我们希望在测试阶段收集激活统计信息。注意，我们还使用了```-e```命令行参数来表示我们希望运行测试阶段。另外两个合法参数值是```train```和```valid```，它们分别在训练和验证阶段收集激活统计信息。

## Collectors and their collaterals
ActivationStatsCollector子类的一个实例可用于收集激活统计信息。当前，ActivationStatsCollector有两种类型的子类:SummaryActivationStatsCollector和RecordsActivationStatsCollector。
SummaryActivationStatsCollector的实例计算某个激活统计值的平均值。与每次激活收集记录相比，它是相当轻量级和快速的。统计函数在构造函数中配置。
在示例压缩应用程序compress_classifier中。在py中，我们创建一个收集器字典。例如:进入翻译页面
```python
SummaryActivationStatsCollector(model,
                                "sparsity",
                                lambda t: 100 * distiller.utils.sparsity(t))
```

在前传过程中遇到的每个激活都会调用lambda表达式，它返回的值(在本例中是激活张量的稀疏度乘以100)存储在模块中。稀疏性(“稀疏性”是这个收藏家的名字)。要访问统计信息，可以调用collector.value()，或者直接访问每个模块的数据。


另一种类型的收集器是RecordsActivationStatsCollector，它计算一组硬编码的activations统计信息，并收集每个激活的记录。由于明显的原因，这比SummaryActivationStatsCollector的实例要慢。
ActivationStatsCollector默认只收集ReLU层的输出激活统计信息，但是我们可以选择任何我们想要的层类型。在下面的例子中，我们从torch.nn.Conv2d层的输出中收集统计信息。

```python
RecordsActivationStatsCollector(model, classes=[torch.nn.Conv2d])
```
通过调用collector.to_xlsx(path_to_workbook)，收集器可以将其数据写入Excel工作簿(使用收集器的名称命名)。在compress_classider .py中，我们目前创建了四个不同的收集器，您可以选择性地禁用它们。还可以添加其他统计信息收集器，并使用不同的函数来计算新的统计信息。
```python
collectors = missingdict({
    "sparsity":      SummaryActivationStatsCollector(model, "sparsity",
                                                     lambda t: 100 * distiller.utils.sparsity(t)),
    "l1_channels":   SummaryActivationStatsCollector(model, "l1_channels",
                                                     distiller.utils.activation_channels_l1),
    "apoz_channels": SummaryActivationStatsCollector(model, "apoz_channels",
                                                     distiller.utils.activation_channels_apoz),
    "records":       RecordsActivationStatsCollector(model, classes=[torch.nn.Conv2d])})
```
默认情况下，这些收集器将其数据写入活动日志目录中的文件。
你可以使用效用函数，蒸馏器。log_activation_statsitics，用于将ActivationStatsCollector实例的数据记录到一个后端日志记录器。例如，下面的代码将“稀疏性”收集器记录到一个TensorBoard日志文件中。
```python
distiller.log_activation_statsitics(epoch, "train", loggers=[tflogger],
                               collector=collectors["sparsity"])
```

##说明
蒸馏器使用PyTorch的前钩机制收集激活统计数据。收集器迭代地注册模块的前钩，收集器在前向遍历期间被调用，并公开激活数据。注册正向回调是这样执行的:
```python
module.register_forward_hook
```
这使得这种机制有两个明显的局限性:


我们只能注册PyTorch模块。这意味着我们不能在像torch.nn.functional.relu和torch.nn.functional.max_pool2d这样的泛函的前钩上注册。
因此，您可能需要用它们的模块替代函数。例如:
```python
class MadeUpNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return x
```
可更改为:
```python
class MadeUpNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.relu = nn.ReLU(inplace=True)

    def forward(self, x):
        x = self.relu(self.conv1(x))
        return x
```

我们只能在模型中使用一个模块实例一次。如果我们多次使用同一个模块，那么我们无法确定图中的哪个节点调用了回调，因为PyTorch回调签名def hook(模块、输入、输出)没有提供足够的上下文信息。
TorchVision的ResNet就是一个使用同一个nn实例ReLU多次的模型的例子:

```python
class BasicBlock(nn.Module):
    expansion = 1
    def __init__(self, inplanes, planes, stride=1, downsample=None):
        super(BasicBlock, self).__init__()
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.bn1 = nn.BatchNorm2d(planes)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = conv3x3(planes, planes)
        self.bn2 = nn.BatchNorm2d(planes)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x):
        residual = x
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)                    # <================
        out = self.conv2(out)
        out = self.bn2(out)
        if self.downsample is not None:
            residual = self.downsample(x)
        out += residual
        out = self.relu(out)                    # <================
        return out
```
在Distiller中，我们将[ResNet](https://github.com/NervanaSystems/distiller/blob/master/models/imagenet/resnet.py)改为使用nn.ReLU的多个实例。，每个实例只使用一次:
```python
class BasicBlock(nn.Module):
    expansion = 1
    def __init__(self, inplanes, planes, stride=1, downsample=None):
        super(BasicBlock, self).__init__()
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.bn1 = nn.BatchNorm2d(planes)
        self.relu1 = nn.ReLU(inplace=True)
        self.conv2 = conv3x3(planes, planes)
        self.bn2 = nn.BatchNorm2d(planes)
        self.relu2 = nn.ReLU(inplace=True)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x):
        residual = x
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu1(out)                   # <================
        out = self.conv2(out)
        out = self.bn2(out)
        if self.downsample is not None:
            residual = self.downsample(x)
        out += residual
        out = self.relu2(out)                   # <================
        return out
```

##使用Jupyter notebooks
Jupyter notebooks包含了许多如何使用统计摘要产生的蒸馏器的例子。它们在另一页中进行了解释。

##生成这个文档
执行以下命令安装mkdocs和所需的软件包:
```shell script
$ pip3 install -r doc-requirements.txt0
```
要构建项目文档，请运行:
```shell script
$ cd distiller/docs-src
$ mkdocs build --clean
```
这将创建一个名为“site”的文件夹，其中包含文档网站。打开distiller/docs/site/index.html查看文档主页。